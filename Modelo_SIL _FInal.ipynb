{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luis Enrique Camaños Rebollo      \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import itertools as iter\n",
    "from sklearn.metrics import accuracy_score,recall_score\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Separa los datos por clase\n",
    "def define_class_dataset(name_class, class_list,setInicial):\n",
    "    class_datasets = {}\n",
    "    for item, clase in enumerate(class_list):\n",
    "        variable_name = f\"class_{item + 1}\"\n",
    "        class_datasets[variable_name] = setInicial.loc[setInicial[name_class] == clase].copy()\n",
    "    return class_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Proceso aleatorio\n",
    "def randomize_dataset(dataset):\n",
    "    return dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Proceso de estratificación\n",
    "def stratification_dataset(datasets_dictionary, percentage):\n",
    "    train_sets = {}\n",
    "    test_sets = {}\n",
    "    for variable_name, dataset in datasets_dictionary.items():\n",
    "        tope = math.floor(len(dataset) * percentage)\n",
    "        train_sets[variable_name] = dataset.iloc[0:tope]\n",
    "        test_sets[variable_name] = dataset.iloc[tope:len(dataset)]\n",
    "    return train_sets, test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definición de hiperparámetros\n",
    "def hiper_parameters_definition():\n",
    "    neuronas = [8,12,15,17]\n",
    "    capas_ocultas = [1,3,5]\n",
    "    learning_rate_i = [0.12,0.1,0.05]\n",
    "    momentum = [0.12,0.1,0.05]\n",
    "    combinaciones = list(iter.product(neuronas,capas_ocultas,learning_rate_i,momentum))\n",
    "    return neuronas,capas_ocultas,learning_rate_i,momentum,combinaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definición de tamaño de pliegues\n",
    "def num_values_def(train_sets,NumPliegues):\n",
    "    num_values = {}\n",
    "    cont = {}\n",
    "    for variable_name, dataset in train_sets.items():\n",
    "        num_values[variable_name] = int(len(dataset)/NumPliegues)\n",
    "        cont[variable_name] = 0\n",
    "    return num_values,cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cross_validation(train_sets,topes_dic,cont):\n",
    "    test_A_dic = {}\n",
    "    cont01 = 0\n",
    "    for variable_name,dataset in train_sets.items():\n",
    "        topes_values_list = list(topes_dic.values())\n",
    "        cont_values_list = list(cont.values())\n",
    "        test_A_dic[variable_name] = dataset.iloc[cont_values_list[cont01]:topes_values_list[cont01]]\n",
    "        cont01+=1\n",
    "    Test_A = pd.concat(list(test_A_dic.values())).copy()\n",
    "    return Test_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross_validation(train_sets,topes_dic,cont):\n",
    "    cont02 = 0\n",
    "    train_A_dic = {}\n",
    "    for variable_name,dataset in train_sets.items():\n",
    "        topes_values_list = list(topes_dic.values())\n",
    "        cont_values_list = list(cont.values())\n",
    "        train_A_dic[variable_name] = pd.concat([dataset.iloc[0:cont_values_list[cont02]],\n",
    "                                                    dataset.iloc[topes_values_list[cont02]:len(dataset)]],\n",
    "                                                    axis=0)\n",
    "    Train_A = pd.concat(list(train_A_dic.values())).copy()\n",
    "    return Train_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_definition(combinacion,epoca):\n",
    "    lista_neurona = []\n",
    "    for i in range(combinacion[1]):\n",
    "        lista_neurona.append(combinacion[0])\n",
    "    clf = MLPClassifier(\n",
    "                  hidden_layer_sizes= lista_neurona,\n",
    "                  solver='adam',\n",
    "                  learning_rate='adaptive',\n",
    "                  learning_rate_init=combinacion[2],\n",
    "                  max_iter=int(epoca),\n",
    "                  momentum=combinacion[3],\n",
    "                  random_state = 1,\n",
    "              )\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desviacion_estandar_calc(lista_valores):\n",
    "    desviacion_estandar = statistics.stdev(lista_valores)\n",
    "    promedio = statistics.mean(lista_valores)\n",
    "    return desviacion_estandar,promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_lista_final(listas):\n",
    "    parametros_finales = []\n",
    "    for i in range(len(listas[0])):  \n",
    "        valores = [lista[i] for lista in listas]\n",
    "        if all(val == valores[0] for val in valores):\n",
    "            parametros_finales.append(valores[0])\n",
    "        else:\n",
    "            min_valor = min(valores)\n",
    "            if min_valor >= 1:\n",
    "                min_valor = int(min_valor)\n",
    "            max_valor = max(valores)\n",
    "            if max_valor >= 1:\n",
    "                max_valor = int(max_valor)\n",
    "            valor_medio = round(sum(valores) / len(valores), 2)\n",
    "            if valor_medio >= 1:\n",
    "                valor_medio = int(valor_medio)\n",
    "            parametros_finales.append([min_valor, max_valor, valor_medio])\n",
    "    return parametros_finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinaciones_final_def(lista):\n",
    "    for i in range(len(lista)):\n",
    "        if not isinstance(lista[i], list):\n",
    "            lista[i] = [lista[i]]\n",
    "    neuronas = lista[0]\n",
    "    capas_ocultas = lista[1]\n",
    "    learning_rate_i = lista[2]\n",
    "    momentum = lista[3]\n",
    "    combinaciones_finales = list(iter.product(neuronas,capas_ocultas,learning_rate_i,momentum))\n",
    "    return combinaciones_finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Lectura de base de datos tratada, extracción de atributos y clases, definición de pocentaje \n",
    "    #Train y Test\n",
    "    setInicial = pd.read_csv('FINALdbCANCER.csv')\n",
    "    atributosName = setInicial.columns[:-1]\n",
    "    atributosClase = setInicial.columns[-1]\n",
    "    clasesName = setInicial[setInicial.columns[-1]].drop_duplicates()\n",
    "    clasesList = setInicial[atributosClase].unique().tolist()\n",
    "    percentage = 0.75\n",
    "    #Separación de datos por clase para futura estratificación\n",
    "    class_datasets = define_class_dataset(atributosClase, clasesList,setInicial)\n",
    "    #Proceso aleatorio a los datos de cada clase\n",
    "    for variable_name, dataset in class_datasets.items():\n",
    "        class_datasets[variable_name] = randomize_dataset(dataset)\n",
    "    #Proceso de estratificación que genera los sets Train y Test por clase\n",
    "    train_sets, test_sets = stratification_dataset(class_datasets, percentage)\n",
    "    #Generación de conjunto Test y aplicación de proceso aleatorio para eliminar sesgos\n",
    "    TestG = pd.concat(list(test_sets.values())).copy()\n",
    "    TestG = randomize_dataset(TestG)\n",
    "    #Generación de conjunto Train y aplicación de proceso aleatorio para eliminar sesgos\n",
    "    TrainG = pd.concat(list(train_sets.values())).copy()\n",
    "    TrainG = randomize_dataset(TrainG)\n",
    "    #Definición de número de pliegues para cross-validation (K) \n",
    "    NumPliegues=3\n",
    "    num_values,cont = num_values_def(train_sets,NumPliegues)\n",
    "    #Ciclo principal para cross-validation\n",
    "    accuracy_list = []\n",
    "    combinacion_list = []\n",
    "    recall_list = []\n",
    "    for x in range(1,NumPliegues+1,1):\n",
    "        print(\"Pliegue \",x)\n",
    "        topes_dic = {}\n",
    "        #Definición de tamaño de particiones con base en los pliegues\n",
    "        if x==NumPliegues:\n",
    "            for variable_name,dataset in train_sets.items():\n",
    "                topes_dic[variable_name] = len(dataset)\n",
    "        else:\n",
    "            for key in sorted(set(cont.keys()) & set(num_values.keys())):\n",
    "                result = cont[key] + num_values[key]\n",
    "                topes_dic[key] = result\n",
    "        #Obtención de conjunto Test de validación cruzada y aplicación de proceso aleatorio\n",
    "        Test_A = test_cross_validation(train_sets,topes_dic,cont)\n",
    "        Test_A = randomize_dataset(Test_A)\n",
    "        #Obtención de conjunto Train de validación cruzada y aplicación de proceso aleatorio\n",
    "        Train_A = train_cross_validation(train_sets,topes_dic,cont)\n",
    "        Train_A = randomize_dataset(Train_A)\n",
    "        #Corrimiento de posición para definir nuevo Test y Train para el siguiente pliegue\n",
    "        print(\"Train: \",len(Train_A),\" intancias.\\nTest: \",len(Test_A),\" instancias.\")\n",
    "        for key in sorted(set(cont.keys()) & set(num_values.keys())):\n",
    "            result = cont[key] + num_values[key]\n",
    "            cont[key] = result\n",
    "        #Asociación de etiquetas con los datos\n",
    "        valoresTrain=Train_A[atributosName]\n",
    "        valoresTest=Test_A[atributosName]\n",
    "        clasesTrain=Train_A[atributosClase]\n",
    "        clasesTest=Test_A[atributosClase]\n",
    "        #ODefinición de hiperparámetros y sus combinaciones \n",
    "        neuronas,capas_ocultas,learning_rate_i,momentum,combinaciones = hiper_parameters_definition()\n",
    "        epoca_inicial = 1\n",
    "        epoca_final = 250\n",
    "        paso = 10\n",
    "        #Ciclo principal de búsqueda de la rejilla\n",
    "        #Iteración por combinaciones\n",
    "        #Definición de parámetros iniciales para obtener el mejor modelo\n",
    "        epoca_ideal = 0\n",
    "        accuracy_test_ideal = 0\n",
    "        accuracy_train_ideal = 0\n",
    "        combinacion_ideal = []\n",
    "        training_error_ideal = []\n",
    "        test_error_ideal = []\n",
    "        epoca_list_ideal = []\n",
    "        recall_ideal = 0\n",
    "        error_min = 1\n",
    "        for combinacion in combinaciones:\n",
    "            training_error = []\n",
    "            test_error = []\n",
    "            epoca_list = [] \n",
    "            #Ciclo para probar experimentos por diferentes épocas\n",
    "            for epoca in range(epoca_inicial,epoca_final,paso):\n",
    "                #Definición del modelo\n",
    "                clf_regular = model_definition(combinacion,epoca)\n",
    "                #Entrenamiento del modelo\n",
    "                clf_regular.fit(valoresTrain, clasesTrain)\n",
    "                #Obtención de etiquetas predichas con el conjunto Test\n",
    "                predicted_values = clf_regular.predict(valoresTest)\n",
    "                #Obtención de accuracy y error en el conjunto Test\n",
    "                accuracy_test = accuracy_score(clasesTest,predicted_values)\n",
    "                error_test = 1 - accuracy_test\n",
    "                #Obtención de accuracy y error en el conjunto Train\n",
    "                accuracy_train = clf_regular.score(valoresTrain,clasesTrain)\n",
    "                error_train = 1 - accuracy_train\n",
    "                #Recall\n",
    "                recall_test = recall_score(clasesTest,predicted_values,pos_label='M',average='binary')\n",
    "                #Registro de errores y épocas\n",
    "                training_error.append(error_train)\n",
    "                test_error.append(error_test)\n",
    "                epoca_list.append(epoca)\n",
    "                #Obtención de los parámetros ideales en función del error mínimo\n",
    "                if error_test < error_min:\n",
    "                    error_min = error_test\n",
    "                    combinacion_ideal = combinacion\n",
    "                    epoca_ideal = epoca\n",
    "                    accuracy_test_ideal = accuracy_test\n",
    "                    accuracy_train_ideal = accuracy_train\n",
    "                    training_error_ideal = training_error\n",
    "                    test_error_ideal = test_error\n",
    "                    epoca_list_ideal = epoca_list\n",
    "                    recall_ideal = recall_test\n",
    "        #Registro de accuracy\n",
    "        recall_list.append(recall_ideal)\n",
    "        accuracy_list.append(accuracy_test_ideal)\n",
    "        combinacion_list.append(combinacion_ideal)\n",
    "        #Impresión de resultados\n",
    "        print(\"Train accuracy: \", accuracy_train_ideal)\n",
    "        print(\"Test accuracy: \", accuracy_test_ideal)\n",
    "        print(\"Recall: \",recall_ideal)\n",
    "        print(\"Best hiperparameters\")\n",
    "        print(\"Hidden layers: \",combinacion_ideal[1])\n",
    "        print(\"Neurons: \",combinacion_ideal[0])\n",
    "        print(\"Learnig Rate: \",combinacion_ideal[2])\n",
    "        print(\"Momentum: \",combinacion_ideal[3])\n",
    "        print(\"Épocas: \",epoca_ideal)\n",
    "        plt.plot(epoca_list_ideal, training_error_ideal, label=\"training error\")\n",
    "        plt.plot(epoca_list_ideal, test_error_ideal, label=\"test error\")\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.xlabel(\"Épocas\")\n",
    "        plt.ylim(0, 1.0)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    valoresTrain_=TrainG[atributosName]\n",
    "    valoresTest_=TestG[atributosName]\n",
    "    clasesTrain_=TrainG[atributosClase]\n",
    "    clasesTest_=TestG[atributosClase]\n",
    "    print(recall_list)\n",
    "    standar_dev,promedio = desviacion_estandar_calc(recall_list)\n",
    "\n",
    "    print(\"La desviación estandar fue de: \",standar_dev)\n",
    "    print(\"EL promedio fue de: \",promedio)\n",
    "    print(\"Validación Final\")\n",
    "    print(\"Train: \",len(TrainG),\" intancias.\\nTest: \",len(TestG),\" instancias.\")\n",
    "    parametros_finales = construir_lista_final(combinacion_list)\n",
    "    combinaciones_finales_ = combinaciones_final_def(parametros_finales)\n",
    "    epoca_ideal_ = 0\n",
    "    accuracy_test_ideal_ = 0\n",
    "    accuracy_train_ideal_ = 0\n",
    "    combinacion_ideal_ = []\n",
    "    training_error_ideal_ = []\n",
    "    test_error_ideal_ = []\n",
    "    epoca_list_ideal_ = []\n",
    "    error_min_ = 1\n",
    "    recall_ideal_ = 0\n",
    "    for combinacion in combinaciones_finales_:\n",
    "        training_error_ = []\n",
    "        test_error_ = []\n",
    "        epoca_list_ = []\n",
    "        for epoca in range(epoca_inicial,epoca_final,paso):\n",
    "                #Definición del modelo\n",
    "                clf_regular_ = model_definition(combinacion,epoca)\n",
    "                #Entrenamiento del modelo\n",
    "                clf_regular_.fit(valoresTrain_, clasesTrain_)\n",
    "                #Obtención de etiquetas predichas con el conjunto Test\n",
    "                predicted_values_ = clf_regular_.predict(valoresTest_)\n",
    "                #Obtención de accuracy y error en el conjunto Test\n",
    "                accuracy_test_ = accuracy_score(clasesTest_,predicted_values_)\n",
    "                error_test_ = 1 - accuracy_test_\n",
    "                #Obtención de accuracy y error en el conjunto Train\n",
    "                accuracy_train_ = clf_regular_.score(valoresTrain_,clasesTrain_)\n",
    "                error_train_ = 1 - accuracy_train_\n",
    "                #Recall\n",
    "                recall_test_ = recall_score(clasesTest_,predicted_values_,pos_label='M',average='binary')\n",
    "                #Registro de errores y épocas\n",
    "                training_error_.append(error_train_)\n",
    "                test_error_.append(error_test_)\n",
    "                epoca_list_.append(epoca) \n",
    "                #Obtención de los parámetros ideales en función del error mínimo\n",
    "                if error_test_ < error_min_:\n",
    "                    error_min_ = error_test_\n",
    "                    combinacion_ideal_ = combinacion\n",
    "                    epoca_ideal_ = epoca\n",
    "                    accuracy_test_ideal_ = accuracy_test_\n",
    "                    accuracy_train_ideal_ = accuracy_train_\n",
    "                    training_error_ideal_ = training_error_\n",
    "                    test_error_ideal_ = test_error_\n",
    "                    epoca_list_ideal_ = epoca_list_\n",
    "                    recall_ideal_ = recall_test_\n",
    "    print(\"Train accuracy: \", accuracy_train_ideal_)\n",
    "    print(\"Test accuracy: \", accuracy_test_ideal_)\n",
    "    print(\"Recall: \",recall_ideal_)\n",
    "    print(\"Best hiperparameters\")\n",
    "    print(\"Hidden layers: \",combinacion_ideal_[1])\n",
    "    print(\"Neurons: \",combinacion_ideal_[0])\n",
    "    print(\"Learnig Rate: \",combinacion_ideal_[2])\n",
    "    print(\"Momentum: \",combinacion_ideal_[3])\n",
    "    print(\"Épocas: \",epoca_ideal_)\n",
    "    plt.plot(epoca_list_ideal_, training_error_ideal_, label=\"training error\")\n",
    "    plt.plot(epoca_list_ideal_, test_error_ideal_, label=\"test error\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
